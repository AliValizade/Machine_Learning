{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib Qt\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from modules import Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>b</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "\n",
       "        b  lstat  medv  \n",
       "0  396.90   4.98  24.0  \n",
       "1  396.90   9.14  21.6  \n",
       "2  392.83   4.03  34.7  \n",
       "3  394.63   2.94  33.4  \n",
       "4  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/BostonHousing.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['rm', 'age']].values\n",
    "Y = data['medv'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data ==> Xnorm = (Xâˆ’mean) / std\n",
    "X_mean = np.mean(X, axis=0)\n",
    "X_std = np.std(X, axis=0)\n",
    "X = (X - X_mean) / X_std\n",
    "\n",
    "Y_mean = np.mean(Y)\n",
    "Y_std = np.std(Y)\n",
    "Y = (Y - Y_mean) / Y_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_w = 0.0001\n",
    "learning_rate_b = 0.001\n",
    "Epoch = 0\n",
    "stop_condition = False\n",
    "loss_threshold = 0.001  # Threshold for stopping condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.1223723851551415\n",
      "Epoch 2, Loss: 1.0710408109921938\n",
      "Epoch 3, Loss: 1.028026631184246\n",
      "Epoch 4, Loss: 0.990556186540791\n",
      "Epoch 5, Loss: 0.9555424309733549\n",
      "Epoch 6, Loss: 0.923010695059445\n",
      "Epoch 7, Loss: 0.8923002213687229\n",
      "Epoch 8, Loss: 0.8631133433906109\n",
      "Epoch 9, Loss: 0.8355909187810694\n",
      "Epoch 10, Loss: 0.8094720343715787\n",
      "Epoch 11, Loss: 0.7849884544388702\n",
      "Epoch 12, Loss: 0.7617795795575132\n",
      "Epoch 13, Loss: 0.7397568438197932\n",
      "Epoch 14, Loss: 0.7190467249552303\n",
      "Epoch 15, Loss: 0.6995456141280354\n",
      "Epoch 16, Loss: 0.6813410271190055\n",
      "Epoch 17, Loss: 0.6643338806642638\n",
      "Epoch 18, Loss: 0.6482459665088912\n",
      "Epoch 19, Loss: 0.6329361414938632\n",
      "Epoch 20, Loss: 0.618426144909066\n",
      "Epoch 21, Loss: 0.6048857356931704\n",
      "Epoch 22, Loss: 0.5921916575378904\n",
      "Epoch 23, Loss: 0.5803622578834905\n",
      "Epoch 24, Loss: 0.5693535624398519\n",
      "Epoch 25, Loss: 0.5590461524343187\n",
      "Epoch 26, Loss: 0.549295616203351\n",
      "Epoch 27, Loss: 0.5401271298879322\n",
      "Epoch 28, Loss: 0.5314842118872013\n",
      "Epoch 29, Loss: 0.5233766729935557\n",
      "Epoch 30, Loss: 0.5159896778056746\n",
      "Epoch 31, Loss: 0.5091998684656456\n",
      "Epoch 32, Loss: 0.5027990300782249\n",
      "Epoch 33, Loss: 0.4969244318103277\n",
      "Epoch 34, Loss: 0.4915491017254509\n",
      "Epoch 35, Loss: 0.4866286808364285\n",
      "Epoch 36, Loss: 0.4819785767524019\n",
      "Epoch 37, Loss: 0.47775069135656223\n",
      "Epoch 38, Loss: 0.47400339026974997\n",
      "Epoch 39, Loss: 0.4706254547453129\n",
      "Epoch 40, Loss: 0.46755365508980795\n",
      "Epoch 41, Loss: 0.4646980556980225\n",
      "Epoch 42, Loss: 0.4620492532825083\n",
      "Epoch 43, Loss: 0.4597299922712685\n",
      "Epoch 44, Loss: 0.4578046795441111\n",
      "Epoch 45, Loss: 0.45603391054620157\n",
      "Epoch 46, Loss: 0.4544190230191526\n",
      "Epoch 47, Loss: 0.45292834877686444\n",
      "Epoch 48, Loss: 0.45153351027050903\n",
      "Epoch 49, Loss: 0.45025008046195897\n",
      "Epoch 50, Loss: 0.44908987588056626\n",
      "Epoch 51, Loss: 0.4480291803146206\n",
      "Epoch 52, Loss: 0.44708160244355977\n",
      "Epoch 53, Loss: 0.4462371032927443\n",
      "Epoch 54, Loss: 0.4454665942218809\n",
      "Epoch 55, Loss: 0.44473089877036553\n",
      "Epoch 56, Loss: 0.4440408291132398\n",
      "Epoch 57, Loss: 0.4434046384340268\n",
      "Epoch 58, Loss: 0.4428455948454287\n",
      "Epoch 59, Loss: 0.44231623140311693\n",
      "Epoch 60, Loss: 0.4418206261258957\n",
      "Epoch 61, Loss: 0.4413750398776483\n",
      "Epoch 62, Loss: 0.4409767391982843\n",
      "Epoch 63, Loss: 0.44064735235284974\n",
      "Epoch 64, Loss: 0.44035350398372775\n",
      "Epoch 65, Loss: 0.4401114356542258\n",
      "Epoch 66, Loss: 0.43989185180595797\n",
      "Epoch 67, Loss: 0.43968382940272366\n",
      "Epoch 68, Loss: 0.4395097881704914\n",
      "Epoch 69, Loss: 0.4393450909063454\n",
      "Epoch 70, Loss: 0.4392146307137398\n",
      "Epoch 71, Loss: 0.43910651417862023\n",
      "Epoch 72, Loss: 0.4390043674000565\n",
      "Epoch 73, Loss: 0.4389078800630811\n",
      "Epoch 74, Loss: 0.4388235195327282\n",
      "Epoch 75, Loss: 0.43875074675812703\n",
      "Epoch 76, Loss: 0.43869903380210606\n",
      "Epoch 77, Loss: 0.43866602597759\n",
      "Epoch 78, Loss: 0.438635540919083\n",
      "Epoch 79, Loss: 0.43861362089410205\n",
      "Epoch 80, Loss: 0.4386078223956\n"
     ]
    }
   ],
   "source": [
    "# Create and train the model\n",
    "perceptron = Perceptron(input_size=2, lr_w=learning_rate_w, lr_b=learning_rate_b, epoch=Epoch, loss_threshold=loss_threshold)\n",
    "perceptron.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.043764818900612\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "loss = perceptron.evaluate(X_test, Y_test)\n",
    "print(f\"Test Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "Y_pred = perceptron.predict(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert normalized data back to original scale\n",
    "X_train_original = X_train * X_std + X_mean\n",
    "Y_train_original = Y_train * Y_std + Y_mean\n",
    "Y_pred_original = Y_pred * Y_std + Y_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Scatter plot\n",
    "ax.scatter(X_train_original[:, 0], X_train_original[:, 1], Y_train_original, color='blue', label='Training Data')\n",
    "\n",
    "# Animation function\n",
    "def update(num):\n",
    "    ax.clear()\n",
    "    ax.scatter(X_train_original[:, 0], X_train_original[:, 1], Y_train_original, color='blue', label='Training Data')\n",
    "    \n",
    "    # Update prediction for each frame\n",
    "    Y_pred = np.dot(X_train, perceptron.w) + perceptron.b\n",
    "    # Y_pred_original = Y_pred * Y_std + Y_mean\n",
    "\n",
    "    # Create a meshgrid for the plane\n",
    "    x_surf, y_surf = np.meshgrid(np.linspace(X_train_original[:, 0].min(), X_train_original[:, 0].max(), 100),\n",
    "                                 np.linspace(X_train_original[:, 1].min(), X_train_original[:, 1].max(), 100))\n",
    "    z_surf = perceptron.w[0] * (x_surf - X_mean[0]) / X_std[0] + perceptron.w[1] * (y_surf - X_mean[1]) / X_std[1] + perceptron.b\n",
    "    z_surf = z_surf * Y_std + Y_mean\n",
    "    \n",
    "    ax.plot_surface(x_surf, y_surf, z_surf, color='red', alpha=0.5)\n",
    "    ax.set_xlabel('ROOM')\n",
    "    ax.set_ylabel('AGE')\n",
    "    ax.set_zlabel('Average House Price')\n",
    "    ax.set_title(f'Perceptron Linear Regression (Epoch: {num})\\nBostonHousing')\n",
    "\n",
    "ani = animation.FuncAnimation(fig, update, frames=len(perceptron.losses), repeat=False)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
